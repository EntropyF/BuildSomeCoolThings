{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From resnet_model_jf.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Train the model on the training set\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Move the data to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the training loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Print status every 10 batches\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Save the model every 4 epochs starting from epoch 10\n",
    "    if (epoch >= 3 and epoch % 2 == 0) or epoch == num_epochs - 1:\n",
    "        save_path=os.path.join(os.getcwd(), f\"../output/v3_test_2207_resnet50_256_epoch_{epoch+1}.pth\")\n",
    "        #save_path = f\"saved_models/model_epoch_{epoch}.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Model saved at {save_path}\")\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(val_loader):\n",
    "            # Move the data to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update the test loss and accuracy\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    # Print the training and test loss and accuracy\n",
    "    train_loss /= len(train_dataset)\n",
    "    test_loss /= len(val_dataset)\n",
    "    test_acc = test_acc.double() / len(val_dataset)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Train Loss: {train_loss:.4f} Test Loss: {test_loss:.4f} Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    LIME model to explain resnet50\n",
    "    slow and confusing, abondon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "from skimage.segmentation import quickshift, mark_boundaries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to get model predictions for Lime\n",
    "def batch_predict(images):\n",
    "    model.eval()\n",
    "    pil_images = [Image.fromarray(image.astype('uint8'), 'RGB') for image in images]\n",
    "    batch = torch.stack([transform(image) for image in pil_images], dim=0)\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(batch)\n",
    "    return torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "# Load the image\n",
    "# img_path = os.path.join(os.getcwd(), \"../parsed_data/selected_images/MICROSOFT/MICROSOFT.20180213.91886A548BC3B41FA0C0148C47F19A07.jpg\")\n",
    "img_path = 'Data/KnownImages/UrlScreenshotNew/MTBANK.20190528.3C42F865D0CF7AC06FA3CB78A0C1BC67.png'\n",
    "# img = Image.open(img_path).convert('RGB')\n",
    "with zipfile.ZipFile(raw_data_path, 'r') as zip_ref:\n",
    "                with zip_ref.open(img_path) as file:\n",
    "                    img = Image.open(io.BytesIO(file.read())).convert('RGB')\n",
    "\n",
    "# Create a Lime image explainer\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "# Use a faster segmentation algorithm with optimized parameters\n",
    "segmentation_fn = SegmentationAlgorithm('quickshift', kernel_size=10, max_dist=200, ratio=0.2)\n",
    "\n",
    "# Reduce the number of samples for faster explanation\n",
    "explanation = explainer.explain_instance(np.array(img), \n",
    "                                         batch_predict, \n",
    "                                         top_labels=5, \n",
    "                                         hide_color=0, \n",
    "                                         num_samples=200,  # Reduced from 1000 to 200\n",
    "                                         segmentation_fn=segmentation_fn)\n",
    "\n",
    "# Show the top prediction explanation\n",
    "top_label = explanation.top_labels[0]\n",
    "temp, mask = explanation.get_image_and_mask(top_label, positive_only=True, num_features=10, hide_rest=False)\n",
    "\n",
    "# Convert temp to float to allow blending\n",
    "temp = temp.astype(np.float32)\n",
    "\n",
    "# Create a dark overlay\n",
    "dark_overlay = np.zeros_like(temp)\n",
    "dark_overlay[:, :] = [0, 0, 0]  # Black color\n",
    "alpha = 0.6  # Transparency factor for the unrecognized parts\n",
    "\n",
    "# Blend the original image with the dark overlay based on the mask\n",
    "highlighted_image = temp * mask[:, :, np.newaxis] + dark_overlay * (1 - mask[:, :, np.newaxis]) * alpha + temp * (1 - mask[:, :, np.newaxis]) * (1 - alpha)\n",
    "\n",
    "# Clip values to ensure they are within valid range\n",
    "highlighted_image = np.clip(highlighted_image, 0, 255)\n",
    "\n",
    "# Display the image\n",
    "plt.figure()\n",
    "plt.imshow(highlighted_image / 255.0)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Explanation for class: {class_names[top_label]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    grad-CAM using transparency heatmap\n",
    "    important parts can see, not important parts blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "import io\n",
    "import cv2\n",
    "\n",
    "# Define the transform to preprocess the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the trained ResNet50 model\n",
    "def load_model(model_path, num_classes):\n",
    "    model = resnet50(pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Function to load and preprocess the image\n",
    "def load_and_preprocess_image(img_path, transform):\n",
    "    # Choose from zip or folder\n",
    "    with zipfile.ZipFile(raw_data_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(img_path) as file:\n",
    "            img = Image.open(io.BytesIO(file.read())).convert('RGB')\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Hook to extract gradients\n",
    "class SaveFeatures:\n",
    "    def __init__(self, module):\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        self.features = None\n",
    "        self.gradients = None\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output\n",
    "        output.register_hook(self.save_gradient)\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "# Grad-CAM\n",
    "def generate_gradcam(model, img_tensor, target_class):\n",
    "    # Get the feature extractor\n",
    "    target_layer = model.layer4[-1]\n",
    "    save_features = SaveFeatures(target_layer)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(img_tensor)\n",
    "    one_hot_output = torch.FloatTensor(1, output.size()[-1]).zero_().to(device)\n",
    "    one_hot_output[0][target_class] = 1\n",
    "\n",
    "    # Backward pass\n",
    "    model.zero_grad()\n",
    "    output.backward(gradient=one_hot_output, retain_graph=True)\n",
    "\n",
    "    # Get the gradients and the activations\n",
    "    gradients = save_features.gradients.data.cpu().numpy()[0]\n",
    "    activations = save_features.features.data.cpu().numpy()[0]\n",
    "\n",
    "    # Calculate the weights\n",
    "    weights = np.mean(gradients, axis=(1, 2))\n",
    "\n",
    "    # Generate the Grad-CAM heatmap\n",
    "    gradcam = np.zeros(activations.shape[1:], dtype=np.float32)\n",
    "    for i, w in enumerate(weights):\n",
    "        gradcam += w * activations[i]\n",
    "\n",
    "    gradcam = np.maximum(gradcam, 0)\n",
    "    gradcam = cv2.resize(gradcam, (224, 224))\n",
    "    gradcam = gradcam - gradcam.min()\n",
    "    gradcam = gradcam / gradcam.max()\n",
    "    \n",
    "    save_features.close()\n",
    "\n",
    "    return gradcam\n",
    "\n",
    "# Function to make predictions and print the top 5 results\n",
    "def predict_and_show(model, img_path, transform, device, class_names):\n",
    "    img = load_and_preprocess_image(img_path, transform)\n",
    "    img = img.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "        _, preds = torch.topk(outputs, 5, dim=1)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        top_probs = torch.topk(probs, 5, dim=1).values.cpu().numpy()[0]\n",
    "        top_preds = preds.cpu().numpy()[0]\n",
    "\n",
    "    # Display the image\n",
    "    with zipfile.ZipFile(raw_data_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(img_path) as file:\n",
    "            img_show = Image.open(io.BytesIO(file.read())).convert('RGB')\n",
    "    plt.imshow(img_show)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Print the top 5 predictions\n",
    "    for i in range(5):\n",
    "        print(f\"Predicted: {class_names[top_preds[i]]} with probability {top_probs[i]:.4f}\")\n",
    "\n",
    "    # Generate and display Grad-CAM for the top predicted class\n",
    "    gradcam = generate_gradcam(model, img, top_preds[0])\n",
    "\n",
    "    # Create a grayscale heatmap\n",
    "    heatmap = np.uint8(255 * gradcam)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Normalize the heatmap to [0, 1]\n",
    "    heatmap = heatmap / 255.0\n",
    "\n",
    "    # Convert the original image to an array\n",
    "    img_array = np.array(img_show.resize((224, 224))).astype(np.float32) / 255.0\n",
    "\n",
    "    # Blend the heatmap with the original image\n",
    "    transparent_img = img_array * (1 - heatmap[:, :, np.newaxis]) + heatmap[:, :, np.newaxis]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(transparent_img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Grad-CAM for class: {class_names[top_preds[0]]}\")\n",
    "    plt.show()\n",
    "\n",
    "# Path to the trained model\n",
    "model_path = os.path.join(os.getcwd(), \"../output/v3_test_2207_resnet50_256_epoch_10.pth\")\n",
    "raw_data_path = os.getcwd() + \"/../raw_data/Data.zip\"\n",
    "\n",
    "# Load the class names (assuming you have a list of class names)\n",
    "class_names = test_dataset.classes\n",
    "\n",
    "# Initialize the model and load the trained weights\n",
    "num_classes = len(class_names)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(model_path, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Example usage\n",
    "img_path = 'Data/KnownImages/PdfScreenshotNew/ADOBE.20181121.786ABAD536B53E4DE95A8FB535CA6C3A.jpeg'\n",
    "predict_and_show(model, img_path, transform, device, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    multiple image perdiction (top 5 heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import io\n",
    "import cv2\n",
    "import psutil\n",
    "\n",
    "# Define the transform to preprocess the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the trained ResNet50 model\n",
    "def load_model(model_path, num_classes):\n",
    "    model = resnet50(pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Function to load and preprocess the image\n",
    "def load_and_preprocess_image(img_path, transform):\n",
    "    ## Choose from zip or folder\n",
    "    # with zipfile.ZipFile(raw_data_path, 'r') as zip_ref:\n",
    "    #     with zip_ref.open(img_path) as file:\n",
    "    #         img = Image.open(io.BytesIO(file.read())).convert('RGB')\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Hook to extract gradients\n",
    "class SaveFeatures:\n",
    "    def __init__(self, module):\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        self.features = None\n",
    "        self.gradients = None\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output\n",
    "        output.register_hook(self.save_gradient)\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "# Grad-CAM\n",
    "def generate_gradcam(model, img_tensor, target_class):\n",
    "    # Get the feature extractor\n",
    "    target_layer = model.layer4[-1]\n",
    "    save_features = SaveFeatures(target_layer)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(img_tensor)\n",
    "    one_hot_output = torch.FloatTensor(1, output.size()[-1]).zero_().to(device)\n",
    "    one_hot_output[0][target_class] = 1\n",
    "\n",
    "    # Backward pass\n",
    "    model.zero_grad()\n",
    "    output.backward(gradient=one_hot_output, retain_graph=True)\n",
    "\n",
    "    # Get the gradients and the activations\n",
    "    gradients = save_features.gradients.data.cpu().numpy()[0]\n",
    "    activations = save_features.features.data.cpu().numpy()[0]\n",
    "\n",
    "    # Calculate the weights\n",
    "    weights = np.mean(gradients, axis=(1, 2))\n",
    "\n",
    "    # Generate the Grad-CAM heatmap\n",
    "    gradcam = np.zeros(activations.shape[1:], dtype=np.float32)\n",
    "    for i, w in enumerate(weights):\n",
    "        gradcam += w * activations[i]\n",
    "\n",
    "    gradcam = np.maximum(gradcam, 0)\n",
    "    gradcam = cv2.resize(gradcam, (224, 224))\n",
    "    gradcam = gradcam - gradcam.min()\n",
    "    gradcam = gradcam / gradcam.max()\n",
    "    \n",
    "    save_features.close()\n",
    "\n",
    "    return gradcam\n",
    "\n",
    "# Function to make predictions and print the top 5 results\n",
    "def predict_and_show(model, img_paths, transform, device, class_names):\n",
    "    images = [load_and_preprocess_image(img_path, transform).to(device) for img_path in img_paths]\n",
    "    img_tensors = torch.cat(images)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensors)\n",
    "        _, preds = torch.topk(outputs, 5, dim=1)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        top_probs = torch.topk(probs, 5, dim=1).values.cpu().numpy()\n",
    "        top_preds = preds.cpu().numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(15, 5, figsize=(20, 45))\n",
    "    \n",
    "    # Display the images\n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        # with zipfile.ZipFile(raw_data_path, 'r') as zip_ref:\n",
    "        #     with zip_ref.open(img_path) as file:\n",
    "        #         img_show = Image.open(io.BytesIO(file.read())).convert('RGB')\n",
    "        img_show = Image.open(img_path).convert('RGB')\n",
    "        axes[0, i].imshow(img_show)\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Display top predictions and Grad-CAMs\n",
    "    for k in range(5):\n",
    "        for j in range(5):\n",
    "            axes[2*k+1, j].text(0.5, 0.5, f\"{class_names[top_preds[j][k]]}: {top_probs[j][k]:.4f}\", \n",
    "                                fontsize=12, ha='center', va='center')\n",
    "            axes[2*k+1, j].axis('off')\n",
    "            \n",
    "            gradcam = generate_gradcam(model, img_tensors[j].unsqueeze(0), top_preds[j][k])\n",
    "            heatmap = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n",
    "            heatmap = np.float32(heatmap) / 255.0\n",
    "\n",
    "            # with zipfile.ZipFile(raw_data_path, 'r') as zip_ref:\n",
    "            #     with zip_ref.open(img_paths[j]) as file:\n",
    "            #         img_show = Image.open(io.BytesIO(file.read())).convert('RGB')\n",
    "            img_show = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            img_array = np.array(img_show.resize((224, 224))).astype(np.float32) / 255.0\n",
    "            cam = heatmap + np.float32(img_array)\n",
    "            cam = cam / np.max(cam)\n",
    "\n",
    "            axes[2*k+2, j].imshow(cam)\n",
    "            axes[2*k+2, j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Path to the trained model\n",
    "model_path = os.path.join(os.getcwd(), \"../output/v1_2907_resnet50_256_epoch_10.pth\")\n",
    "raw_data_path = os.getcwd() + \"/../raw_data/Data.zip\"\n",
    "\n",
    "# Load the class names (assuming you have a list of class names)\n",
    "# class_names = test_dataset.classes\n",
    "class_names = ['11', 'ADOBE', 'ALIBABA', 'AMAZON', 'AMELI', 'AMERICANEXPRESS', 'AOL', 'APPLE', 'ATT', \n",
    "'BANKOFAMERICA', 'BBVA', 'BNPPARIBAS', 'BRADESCO', 'CAPITALONE', 'CHASE', 'CIBC', 'CITIBANK', 'CREDITAGRICOLE', \n",
    "'DESJARDINS', 'DHL', 'DOCUSIGN', 'DROPBOX', 'EARTHLINK', 'EBAY', 'EXCEL', 'FACEBOOK', 'FEDEX', 'GOOGLE', 'GOVUK', \n",
    "'IMPOTS', 'ING', 'INSTAGRAM', 'ITAU', 'LINKEDIN', 'MAERSK', 'MICROSOFT', 'MTBANK', 'NETFLIX', 'OFFICE365', \n",
    "'ONEDRIVE', 'ONENOTE', 'ORANGE', 'OURTIME', 'OUTLOOK', 'PAYPAL', 'RBC', 'ROUNDCUBE', \n",
    "'SANTANDER', 'SCOTIABANK', 'SHAREPOINT', 'SUNTRUST', 'USAA', 'VISA', 'WEBMAIL', 'WELLSFARGO', 'XFINITY']\n",
    "\n",
    "# Initialize the model and load the trained weights\n",
    "num_classes = len(class_names)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(model_path, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "def get_cpu_usage(interval=1):\n",
    "    \"\"\"\n",
    "    Get the CPU usage percentage.\n",
    "\n",
    "    Parameters:\n",
    "    interval (int): Time in seconds to wait before getting CPU usage. Default is 1 second.\n",
    "\n",
    "    Returns:\n",
    "    float: CPU usage percentage.\n",
    "    \"\"\"\n",
    "    return psutil.cpu_percent(interval=interval)\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"\n",
    "    Get the memory usage percentage.\n",
    "\n",
    "    Returns:\n",
    "    float: Memory usage percentage.\n",
    "    \"\"\"\n",
    "    return psutil.virtual_memory().percent\n",
    "\n",
    "\n",
    "# Example usage with a list of five image paths\n",
    "img_paths = [\n",
    "    '/mnt/batch/tasks/shared/LS_root/mounts/clusters/t-jiajunfu1gpu/code/Users/t-jiajunfu/EDA/../parsed_data/selected_images/11/11.20200328.257E1AF5510F02FBF0E63C10E7911532.jpg',\n",
    "    '/mnt/batch/tasks/shared/LS_root/mounts/clusters/t-jiajunfu1gpu/code/Users/t-jiajunfu/EDA/../parsed_data/selected_images/11/11.20200328.B59F18E0B58D77C8BE8B1BD79B01D76D.jpg',\n",
    "    '/mnt/batch/tasks/shared/LS_root/mounts/clusters/t-jiajunfu1gpu/code/Users/t-jiajunfu/EDA/../parsed_data/selected_images/11/11.20200520.2E20283D2EE4F771F5D5D3F77A30691E.jpg',\n",
    "    '/mnt/batch/tasks/shared/LS_root/mounts/clusters/t-jiajunfu1gpu/code/Users/t-jiajunfu/EDA/../parsed_data/selected_images/ADOBE/ADOBE.20180507.66FF29D06DB1EE163ACA496AB5E5BA3C.jpg',\n",
    "    '/mnt/batch/tasks/shared/LS_root/mounts/clusters/t-jiajunfu1gpu/code/Users/t-jiajunfu/EDA/../parsed_data/selected_images/ADOBE/ADOBE.20180811.3625648BE3987A340B5C6733043D5026.jpg'\n",
    "]\n",
    "predict_and_show(model, img_paths, transform, device, class_names)\n",
    "\n",
    "cpu_usage = get_cpu_usage()\n",
    "memory_usage = get_memory_usage()\n",
    "print(f\"CPU Usage: {cpu_usage}%\")\n",
    "print(f\"Memory Usage: {memory_usage}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
